#!/bin/bash
#SBATCH --job-name="lstm_gpu"
#SBATCH -e lstm_gpu.err
#SBATCH -p gpu_requeue --gres=gpu:3
#SBATCH -c 20
#SBATCH --mem=50GB
#SBATCH -t 1-00:00:00

# srun --pty -p gpu --gres=gpu:teslaM40:2 -t 0-06:00 --mem 50G -c 10 bash

cd multi-ltmle

module load gcc/9.2.0 R/4.3.1

module load python/3.10.11
/n/app/python/3.10.11.conda/bin/python --version # Manually Set Python 3.10.11

source env/bin/activate
module load cuda/12.1

# Ensure the LD_LIBRARY_PATH contains only the necessary CUDA paths for version 12.1:
export LD_LIBRARY_PATH=/n/app/cuda/12.1-gcc-9.2.0/lib64:/n/app/cuda/12.1-gcc-9.2.0/extras/CUPTI/lib64:/usr/lib64

nvcc -V
nvidia-smi

# Log GPU utilization
/n/cluster/bin/job_gpu_monitor.sh &

# Log CPU utilization (every 1 second)
vmstat 1 > cpu_usage.log &

# Run the job
Rscript simulation.R 'tmle-lstm' 1 'FALSE' 'FALSE'